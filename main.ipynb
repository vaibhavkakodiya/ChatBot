{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose your champion\n",
    "#model_id = \"TheBloke/Llama-2-7B-GGML\"\n",
    "model_id = \"model/TheBloke/Llama-2-7B-chat-GGML\"\n",
    "#model_id = \"TheBloke/Llama-2-13B-GGML\"\n",
    "# model_id = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
    "model_path = \"model/llama-2-7b-chat.ggmlv3.q5_0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "config = {'max_new_tokens': 256, 'repetition_penalty': 1.1, 'temperature': 0.1, 'stream': True}\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                           model_type=\"llama\",\n",
    "                                           lib='avx2', #for cpu use\n",
    "                                          #  gpu_layers=110, #110 for 7b, 130 for 13b,\n",
    "                                          #  cache_dir=\"llama model\",\n",
    "                                           **config\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"Write a poem to help me remember the first 10 elements on the periodic table, giving each\n",
    "element its own line.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = llm.tokenize(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'pipeline' execution\n",
    "llm(prompt, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = \"\"\"who is pm of india?\"\"\"\n",
    "llm(prompt2, stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "NUM_TOKENS=0\n",
    "print('-'*4+'Start Generation'+'-'*4)\n",
    "for token in llm.generate(tokens):\n",
    "    print(llm.detokenize(token), end='', flush=True)\n",
    "    NUM_TOKENS+=1\n",
    "time_generate = time.time() - start\n",
    "print('\\n')\n",
    "print('-'*4+'End Generation'+'-'*4)\n",
    "print(f'Num of generated tokens: {NUM_TOKENS}')\n",
    "print(f'Time for complete generation: {time_generate}s')\n",
    "print(f'Tokens per secound: {NUM_TOKENS/time_generate}')\n",
    "print(f'Time per token: {(time_generate/NUM_TOKENS)*1000}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model from openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain_openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\repos\\job-search\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    model_kwargs={'device': device})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q faiss-cpu\n",
    "# !pip install -q lark chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=\"chroma_db\", embedding_function=embeddings)\n",
    "# results_with_scores = vectordb.similarity_search_with_score(\"Andrei Tarkovsky\")\n",
    "# for doc, score in results_with_scores:\n",
    "#     print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fetching a JD for similarity search using Hyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "from langchain.prompts import PromptTemplate\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Please make a job description based on the job topic\n",
    "topic: {topic}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"topic\"], template=prompt_template)\n",
    "\n",
    "hyDE_llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = HypotheticalDocumentEmbedder(\n",
    "#     llm_chain=llm_chain,\n",
    "#     base_embeddings=embeddings\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"topic\": \"Software engineer\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:LLMChain > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Please make a job description based on the job topic\\ntopic: Software engineer\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:LLMChain > 2:llm:ChatOpenAI] [3.68s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Job Description: \\n\\nWe are seeking a highly skilled and experienced Software Engineer to join our dynamic team. The ideal candidate will be responsible for designing, developing, and implementing software solutions to meet the needs of our clients. \\n\\nKey responsibilities include:\\n\\n- Collaborating with cross-functional teams to define, design, and ship new features\\n- Writing clean, maintainable, and efficient code\\n- Troubleshooting and debugging software issues\\n- Conducting code reviews and providing feedback to team members\\n- Keeping up-to-date with the latest industry trends and technologies\\n- Participating in the full software development lifecycle, from concept to deployment\\n\\nQualifications:\\n\\n- Bachelor's degree in Computer Science or related field\\n- Proven work experience as a Software Engineer\\n- Strong proficiency in programming languages such as Java, C++, or Python\\n- Experience with software development tools and methodologies\\n- Excellent problem-solving skills and attention to detail\\n- Ability to work independently and as part of a team\\n\\nIf you are passionate about software development and have a strong technical background, we would love to hear from you. Join us in creating innovative solutions that drive our business forward.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Job Description: \\n\\nWe are seeking a highly skilled and experienced Software Engineer to join our dynamic team. The ideal candidate will be responsible for designing, developing, and implementing software solutions to meet the needs of our clients. \\n\\nKey responsibilities include:\\n\\n- Collaborating with cross-functional teams to define, design, and ship new features\\n- Writing clean, maintainable, and efficient code\\n- Troubleshooting and debugging software issues\\n- Conducting code reviews and providing feedback to team members\\n- Keeping up-to-date with the latest industry trends and technologies\\n- Participating in the full software development lifecycle, from concept to deployment\\n\\nQualifications:\\n\\n- Bachelor's degree in Computer Science or related field\\n- Proven work experience as a Software Engineer\\n- Strong proficiency in programming languages such as Java, C++, or Python\\n- Experience with software development tools and methodologies\\n- Excellent problem-solving skills and attention to detail\\n- Ability to work independently and as part of a team\\n\\nIf you are passionate about software development and have a strong technical background, we would love to hear from you. Join us in creating innovative solutions that drive our business forward.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 229,\n",
      "      \"prompt_tokens\": 23,\n",
      "      \"total_tokens\": 252\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_86156a94a0\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LLMChain] [3.68s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Job Description: \\n\\nWe are seeking a highly skilled and experienced Software Engineer to join our dynamic team. The ideal candidate will be responsible for designing, developing, and implementing software solutions to meet the needs of our clients. \\n\\nKey responsibilities include:\\n\\n- Collaborating with cross-functional teams to define, design, and ship new features\\n- Writing clean, maintainable, and efficient code\\n- Troubleshooting and debugging software issues\\n- Conducting code reviews and providing feedback to team members\\n- Keeping up-to-date with the latest industry trends and technologies\\n- Participating in the full software development lifecycle, from concept to deployment\\n\\nQualifications:\\n\\n- Bachelor's degree in Computer Science or related field\\n- Proven work experience as a Software Engineer\\n- Strong proficiency in programming languages such as Java, C++, or Python\\n- Experience with software development tools and methodologies\\n- Excellent problem-solving skills and attention to detail\\n- Ability to work independently and as part of a team\\n\\nIf you are passionate about software development and have a strong technical background, we would love to hear from you. Join us in creating innovative solutions that drive our business forward.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topic': 'Software engineer',\n",
       " 'text': \"Job Description: \\n\\nWe are seeking a highly skilled and experienced Software Engineer to join our dynamic team. The ideal candidate will be responsible for designing, developing, and implementing software solutions to meet the needs of our clients. \\n\\nKey responsibilities include:\\n\\n- Collaborating with cross-functional teams to define, design, and ship new features\\n- Writing clean, maintainable, and efficient code\\n- Troubleshooting and debugging software issues\\n- Conducting code reviews and providing feedback to team members\\n- Keeping up-to-date with the latest industry trends and technologies\\n- Participating in the full software development lifecycle, from concept to deployment\\n\\nQualifications:\\n\\n- Bachelor's degree in Computer Science or related field\\n- Proven work experience as a Software Engineer\\n- Strong proficiency in programming languages such as Java, C++, or Python\\n- Experience with software development tools and methodologies\\n- Excellent problem-solving skills and attention to detail\\n- Ability to work independently and as part of a team\\n\\nIf you are passionate about software development and have a strong technical background, we would love to hear from you. Join us in creating innovative solutions that drive our business forward.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Software engineer\"\n",
    "hyDE_llm_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_filter(field_name, value, operator):\n",
    "    return {field_name:{\n",
    "        operator: value\n",
    "        }\n",
    "    }\n",
    "            \n",
    "def create_and_filter(salary = None, experience_level = None, job_type = None):\n",
    "    filter = {}\n",
    "    and_filters = []\n",
    "    if salary:\n",
    "        and_filters.append(create_filter(\"salary\", salary, \"$eq\"))\n",
    "        \n",
    "    if experience_level:\n",
    "        and_filters.append(create_filter(\"experience_level\", experience_level, \"$eq\"))\n",
    "        \n",
    "    if job_type:\n",
    "        and_filters.append(create_filter(\"job_type\", job_type, \"$eq\"))\n",
    "\n",
    "    if len(and_filters) > 1:\n",
    "        filter[\"$and\"] = and_filters\n",
    "        return filter\n",
    "    else:\n",
    "        return and_filters[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"software engineer who can design websites\"\n",
    "# salary, experience_level, job_type, start_date, skill = None, \"ENTRY\", None, None, [\"Python\"]\n",
    "salary, experience_level, job_type, start_date, skill = None, \"ENTRY\", \"FULL TIME\", None, None\n",
    "salary, experience_level, job_type, start_date, skill = None, None, None, None, None\n",
    "# salary, experience_level, job_type = None, None, None\n",
    "filter = create_and_filter(experience_level=experience_level, job_type=\"FULL TIME\")\n",
    "print(filter)\n",
    "\n",
    "# filter = {\"experience\": \"ENTRY\"}\n",
    "\n",
    "hyde = hyDE_llm_chain.invoke(query)[\"text\"]\n",
    "print(hyde)\n",
    "vectordb.similarity_search_with_score(query=hyde, filter=filter, k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self query retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"title of the job posted\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"company\",\n",
    "        description=\"Name of the company hiring\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"company_description\",\n",
    "        description=\"description of the hiring company\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"location\",\n",
    "        description=\"location for which the comapy is hiring\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"job_type\",\n",
    "        description=\"Type of the job. One of ['FULL TIME', 'PART TIME', 'CONTRACT']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"experience_level \",\n",
    "        description=\"level of experience required of the candidate. One of ['ENTRY', 'INTERMEDIATE', 'EXPERT']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"requirement\",\n",
    "        description=\"requirements of the hirer for the posted job\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"skill\",\n",
    "        description=\"skills required for the posted job\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"salary\",\n",
    "        description=\"salary offered for the job in usd. One of ['under $5000', '$5000 - $10000', 'above $10000']\",\n",
    "        type=\"string\",\n",
    "    )\n",
    "]\n",
    "document_content_description = \"description about the job\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    # enable_limit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import (\n",
    "    StructuredQueryOutputParser,\n",
    "    get_query_constructor_prompt,\n",
    ")\n",
    "\n",
    "prompt = get_query_constructor_prompt(\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")\n",
    "output_parser = StructuredQueryOutputParser.from_components()\n",
    "query_constructor = prompt | llm | output_parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.format(query=\"dummy question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "\n",
    "args = query_constructor.invoke(\n",
    "    {\n",
    "        \"query\": \"experience as fresher\"\n",
    "    }\n",
    ")\n",
    "print(args)\n",
    "\n",
    "filter = {}\n",
    "\n",
    "# salary, experience, job_type = None, \"ENTRY\", None\n",
    "salary, experience, job_type = None, None, None\n",
    "\n",
    "if salary:\n",
    "    filter[\"salary\"] = {\n",
    "            \"$eq\": salary\n",
    "        }\n",
    "    \n",
    "if experience:\n",
    "    filter[\"experience\"] = {\n",
    "            \"$eq\": experience\n",
    "        }\n",
    "    \n",
    "if job_type:\n",
    "    filter[\"job_type\"] = {\n",
    "            \"$eq\": job_type\n",
    "        }\n",
    "\n",
    "print(filter)\n",
    "\n",
    "vectordb.similarity_search_with_score(query=args.query, filter=filter, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example only specifies a filter\n",
    "retriever.invoke(\"software\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import eq\n",
    "import gradio as gr\n",
    "\n",
    "def fetch_jobs(question, salary, experience, job_type):\n",
    "    filter = {}\n",
    "    if salary:\n",
    "        filter[\"salary\"] = {\n",
    "                \"$eq\": salary\n",
    "            }\n",
    "        \n",
    "    if experience:\n",
    "        filter[\"experience\"] = {\n",
    "                \"$eq\": experience\n",
    "            }\n",
    "        \n",
    "    if job_type:\n",
    "        filter[\"job_type\"] = {\n",
    "                \"$eq\": job_type\n",
    "            }\n",
    "    \n",
    "    return retriever.invoke(question)\n",
    "\n",
    "outputs = gr.List()\n",
    "\n",
    "demo = gr.Interface(fn=fetch_jobs, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
